% -*- root: ../supcom.tex -*-

\section{Multiprocessor architectures} % (fold)
\label{sec:multiprocessor_architectures}

\subsection{Shared memory vs. distributed memory} % (fold)
\label{sub:shared_memory_vs_distributed_memory}

In a shared-memory architecture, all the processors have access to all the available memory, i.e. all the processors have direct access to the global address space.

In a distributed memory system, each processor has only local memory access; data stored in the memory modules associated with other processors can only be reached via explicit message-passing (send/receive commands).

% subsection shared_memory_vs_distributed_memory (end)

\subsection{SMP vs. NUMA and ccNUMA} % (fold)
\label{sub:numa_vs_ccnuma}
There are different variants of shared memory architectures.

\begin{description}
  \item[SMP:] Symmetric MultiProcessor organizations always have uniform memory access times, i.e. memory access times for all processors and memory modules are equal.
  \item[NUMA:] Non-Uniform Memory Access implies that memory access times vary between processors and memory modules. The caches only hold data from local memory, and no mechanisms exist to keep the chaces consistent with the global address space. In principle any processor could read/wirte to/from any memory location in the global address space; but in practice message passing is normally used.
  \item[ccNUMA:] cache coherent Non-Uniform Memory Access organizations have hardware support to keep the chaches consistent. This enables us to better exploit the shared memory programming model, but message passing may still be used.
\end{description}

% subsection numa_vs_ccnuma (end)

\subsection{Example architectures} % (fold)
\label{sub:example_architectures}

\subsubsection{Bus} % (fold)
\label{ssub:bus}

\begin{itemize}
  \item Shared memory, i.e. all processors can access all physical memory.
  \item SMP (Symmetric MultiProcessor) organization.
  \item All memory locations are equidistant to all processors, i.e. they have the same access time.
  \item \emph{Limitation:} The total bandwidth is fixed, given by the bus.
  \item Processors are easily added at low cost, but they must all share the same limiting bus.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[]{illustrations/architectures/bus.pdf}
  \caption{A bus-based organization. The global memory is accessible to every processor.}
  \label{fig:bus}
\end{figure}

% subsubsection bus (end)


\subsubsection{Crossbar (switch-based)} % (fold)

\begin{itemize}
\label{ssub:crossbar}

  \item Shared memory, i.e. all processors can access all physical memory.
  \item SMP organization.
  \item Multiple paths are available between a processor (or I/O-unit) and a memory unit.
  \item \emph{Limitation:} Expanding the system is expensive because the number of parts increases (switches etc.).
  \item Provides good scalability, but expanding the system is expensive. It is therefore only used for smaller systems.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[]{illustrations/architectures/crossbar.pdf}
  \caption{A crossbar interconnect. The global memory is accessible to every processor.}
  \label{fig:crossbar}
\end{figure}
% subsubsection crossbar (end)


\subsubsection{Mesh} % (fold)
\label{ssub:mesh}

\begin{itemize}
  \item Distributed memory, i.e. a message passing architecture consisting of separate nodes communicating with eachother.
  \item Each processor is connected to a few neighbouring processorsin a very regular pattern. In a 2D mesh, each processor is typically connected to 4 neighbouring processors (East, West, North and South), \emph{except} for the processors on the boundary.
  \item The \emph{toroid} is a variant of the mesh topology with special connections between the boundary of the mesh, reducing the worst case hop-count for messages between nodes.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[]{illustrations/architectures/mesh.pdf}
  \caption{A 2D mesh interconnect. Each circle represents a processing element: A CPU, local cache and local memory, i.e. a single processor. Such a processing element is also known as a node.}
  \label{fig:mesh}
\end{figure}

% subsubsection mesh (end)

\subsubsection{NUMA organization} % (fold)
\label{ssub:numa_organization}

\begin{figure}[H]
  \centering
  \includegraphics[]{illustrations/architectures/numa.pdf}
  \caption{Example of a NUMA organization.}
  \label{fig:label}
\end{figure}

% subsubsection numa_organization (end)

% subsection example_architectures (end)

% section multiprocessor_architectures (end)
